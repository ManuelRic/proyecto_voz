<!DOCTYPE html>
<html lang="es">
<head>
    <link rel="icon" href="img/ev_1/logo.png" type="image/x-icon">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WaveNet - DeepMind</title>
    <style>
        body {
            background: linear-gradient(135deg, #121212 0%, #1a1a1a 100%);
            color: #E0E0E0;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
        }

        h1 {
            font-size: 48px;
            color: #c87100;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 20px;
            color: #BBBBBB;
            font-weight: 400;
            margin-top: 0;
        }

        .section, .card {
            margin-bottom: 40px;
            transition: transform 0.3s ease;
        }

        .section:hover, .card:hover {
            transform: translateY(-5px);
        }

        h2 {
            font-size: 32px;
            color: #FFD369;
            border-bottom: 2px solid #c87100;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }

        p, ul {
            font-size: 18px;
            line-height: 1.8;
            color: #FFFFFF;
            margin: 10px 0;
        }

        ul {
            padding-left: 20px;
        }

        li {
            margin-bottom: 10px;
        }

        .highlight {
            color: #FFD369;
            font-weight: bold;
        }

        footer {
            text-align: center;
            margin-top: 40px;
            font-size: 14px;
            color: #BBBBBB;
        }

        #back_button{
            cursor: pointer;
            position:fixed;
            top: 0;
            left: 0;
            filter: invert(100%);
            width: 80px;
            margin: 20px;
        }
        
        #back_button:hover{
            filter: invert(80%);
        }

        .tooltip {
            position: relative;
            display: inline-block;
            color: #FFD369;
            font-weight: bold;
            cursor: pointer;
        }

        .tooltip-text {
            visibility: hidden;
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 5px 10px;
            border-radius: 5px;
            position: absolute;
            z-index: 1;
            bottom: 125%;
            left: 50%;
            transform: translateX(-50%);
            opacity: 0;
            transition: opacity 0.3s;
            white-space: nowrap;
            max-width: 90vw;
            overflow-wrap: break-word;
            box-sizing: border-box;
        }

        .tooltip:hover .tooltip-text {
            visibility: visible;
            opacity: 1;
        }

        .card {
            background: #1e1e1e;
            border-radius: 12px;
            padding: 25px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2);
            border-left: 4px solid #c87100;
            position: relative;
            overflow: hidden;
        }

        .card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, rgba(200, 113, 0, 0.1) 0%, transparent 100%);
            z-index: 0;
        }

        .card-content {
            position: relative;
            z-index: 1;
        }

        .card h2 {
            border-bottom: none;
            padding-bottom: 0;
            margin-bottom: 15px;
            color: #FFD369;
            font-size: 28px;
        }

        .card li::before {
            content: '•';
            color: #c87100;
            font-weight: bold;
            display: inline-block;
            width: 1em;
            margin-left: -1em;
        }

        .audio-comparison {
            display: flex;
            gap: 20px;
            margin-top: 20px;
            flex-wrap: wrap;
        }

        .audio-sample {
            flex: 1;
            min-width: 250px;
            background: #1e1e1e;
            padding: 15px;
            border-radius: 8px;
            border-left: 3px solid #c87100;
        }

        .audio-player {
            width: 100%;
            margin: 10px 0;
        }

        .audio-description {
            font-size: 14px;
            color: #BBBBBB;
            margin-top: 5px;
            font-style: italic;
        }

        audio::-webkit-media-controls-panel {
            background-color: #2a2a2a;
        }

        audio::-webkit-media-controls-play-button,
        audio::-webkit-media-controls-mute-button {
            filter: invert(80%);
        }
        .spectrogram-container {
            display: flex;
            justify-content: space-around;
            align-items: flex-start;
            gap: 30px;
            margin: 30px 0;
        }

        .spectrogram-item {
            flex: 1;
            min-width: 0;
            text-align: center;
        }

        .spectrogram-item img {
            max-height: 400px;
            width: auto;
            max-width: 100%;
            border: 1px solid #444;
            border-radius: 4px;
        }

        .spectrogram-item p {
            margin-top: 10px;
            color: #BBBBBB;
            font-size: 16px;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .spectrogram-container {
                flex-direction: column;
                align-items: center;
            }
            
            .spectrogram-item {
                width: 100%;
                margin-bottom: 20px;
            }
            
            .spectrogram-item img {
                max-height: 250px;
            }
        }
    </style>
</head>
<body>

    <div class="container">
        <header>
            <h1>WaveNet</h1>
            <p class="subtitle">Modelo generativo autoregresivo para la síntesis de audio realista</p>
        </header>

        <img id="back_button" src="img/ev_1/home.png">

        <section class="card">
            <h2>¿Qué es?</h2>
            <div class="card-content">
                <p>
                    WaveNet es un modelo generativo autoregresivo desarrollado por DeepMind que produce directamente ondas de audio crudas (*raw waveforms*). A diferencia de los métodos tradicionales que utilizan concatenación o vocoders paramétricos, WaveNet genera audio muestra por muestra, modelando su distribución probabilística condicional de forma precisa, es decir, es un modelo basado en la síntesis neuronal.
                </p>
            </div>
        </section>

        <section class="section">
            <h2>Convoluciones Causales Dilatadas</h2>
            <p>
                Para preservar la direccionalidad temporal (pasado → futuro), WaveNet emplea <span class="highlight">convoluciones causales</span>. Estas aseguran que cada predicción solo dependa del presente y el pasado, nunca del futuro.
            </p>
            <p>
                Sin embargo, una sola capa de <span class="tooltip"><i>convolución</i><span class="tooltip-text">Operación que se aplica sobre datos (como imágenes, señales de audio o texto) para extraer patrones locales.</span></span> causal tiene un contexto limitado. Para remediar esto, se utilizan <span class="highlight">convoluciones dilatadas</span>, que expanden el campo receptivo de la red exponencialmente sin incrementar drásticamente los parámetros.
            </p>
            
            <img id="wavenet1" src="img/ev_1/wavenet_2.gif">
            <img id="wavenet2" src="img/ev_1/wavenet.gif">
            
            <p>Por otro lado tenemos la <span class="tooltip">dilatación<span class="tooltip-text"><img id="dilatación" style="width: 400px;"  src="img/ev_1/dilatacion.jpg"></span></span> que permite que la red tenga más contexto que con una convolución normal. Es similar a las convoluciones de agrupamiento o estriadas, pero la salida tiene el mismo tamaño que la entrada.</p>
            
        </section>

        <section class="section">
            <h2>Distribuciones Softmax</h2>
            <p>
                 La función softmax es una función matemática que convierte un vector de números reales en una distribución de probabilidad. 
                 Es ampliamente utilizada en redes neuronales, especialmente en las capas de salida cuando se quiere modelar una variable categórica, 
                 como en la generación de texto o audio donde hay que elegir el siguiente símbolo (por ejemplo, una muestra de audio cuantizada).
                 Para modelar la distribución de convoluciones causales dilatadas <span class="tooltip">(Distribución Condicional)</span>
                 usamos la función Softmax ya que puede manejar una gran cantidad de posibles valores de salida y es lo suficientemente flexible para 
                 capturar la complejidad de las señales de audio. 
            </p>
            <p>
                Antes de aplicar la función Softmax, los valores de audio se transforman utilizando la µ-law (ley A), dónde μ = 255. Después de aplicar µ-law,
                 los valores de audio transformados se cuantizan y en el caso de WaveNet, se cuantiza con 256 niveles.
            </p>
            <p>
                Después de cuantizar la señal de audio, cada valor cuantizado representa un nivel diferente. 
                La función Softmax convierte los logits (valores de entrada) en probabilidades para cada uno de los niveles además se asegura
                 que la suma de todas las probabilidades sea igual a 1, permitiendo interpretar los valores como probabilidades 
                de pertenencia a cada uno de los 256 niveles.
            </p>
            <div style="text-align: center;justify-content: center;">
            <img src="img/ev_1/wavenet_3.png">
            </div>
            <p>
                Si el nivel 80 tiene una probabilidad de 0.04, esto significa que, según la función Softmax, la probabilidad de que la siguiente muestra de audio sea cuantizada al nivel 80 es del 4%.
En otras palabras, de todas los posibles niveles cuantizados, el nivel 80 tiene una probabilidad del 4% de ser el valor de la siguiente muestra de audio.

            </p>
        </section>

    <section class="section">
        <h2>Context stacks</h2>
        <p>
            Los Context Stacks son una estructura complementaria que se añade encima del WaveNet principal para aumentar aún más su capacidad para capturar dependencias a largo plazo,
            con ello logramos recordar y usar información de eventos pasados lejanos en el tiempo, cuando está generando o procesando una nueva parte de la señal.
        </p>
        <ul>
            <li>Mantener coherencia en el tono.</li>
            <li>Recordar dónde están las pausas.</li>
            <li>Adaptar la entonación final como en una pregunta (en “¿cómo estás?”).</li>
            <li>Usar un ritmo y prosodia natural desde el principio hasta el final.</li>
        </ul>
        <p>
            Esto ayuda a que al haccer la narración del texto suene fluido sin y natural con pausas del habla imitando el compartamiento más humano.
            Aunque WaveNet ya usa convoluciones dilatadas para aumentar su campo de visión, añadir estas capas ayuda a no aumentar tanto el coste computacional.   
        </p>
    </section>

    <section class="section">
        <h2>Redes de Ondas Condicionales</h2>
        <p>
            WaveNet puede ser extendido para generar audio condicionado a diferentes tipos de entradas. Estas <span class="highlight">redes de ondas condicionales</span>
             permiten que el modelo produzca diferentes resultados basados en contexto adicional.
        </p>
        <ul>
            <li><b>Texto</b>: Condicionamiento con embeddings de texto para síntesis de voz (TTS).</li>
            <li><b>Altavoz</b>: Embeddings del hablante para personalizar la voz generada.</li>
            <li><b>Etiquetas musicales</b>: Para generar música específica por género o instrumento.</li>
        </ul>
    </section>

</div>
    
    <section class="card">
        <h2>Demo Interactiva: Comparación de Técnicas</h2>
        <div class="audio-comparison">
            <div class="audio-sample">
                <h3>WaveNet (Generativo)</h3>
                <audio controls class="audio-player">
                    <source src="audios/us-english-wavenet-1.wav" type="audio/mpeg">
                    Tu navegador no soporta el elemento de audio.
                </audio>
                <p class="audio-description">Audio generado por modelo WaveNet de DeepMind</p>
            </div>
            
            <div class="audio-sample">
                <h3>Paramétrica (Tradicional)</h3>
                <audio controls class="audio-player">
                    <source src="audios/us-english-parametric-1.wav" type="audio/mpeg">
                    Tu navegador no soporta el elemento de audio.
                </audio>
                <p class="audio-description">Audio generado por método paramétrico tradicional</p>
            </div>
        <p>
            Ambos audios son muestras de Google que usan los mismas bases de datos pero las distintas síntensis, es comprobable
            que la paramétrica a pesar de tener una buena calidad de audio al tener en Comparación a wavenet tiene flaquezas debido a 
            tener una síntesis menos actualizada. 
        </p>
        <div class="spectrogram-container">
            <div class="spectrogram-item">
                <img src="img/ev_1/espctrogramama1.png" alt="Espectrograma WaveNet">
                <p>Espectrograma WaveNet</p>
            </div>
            <div class="spectrogram-item">
                <img src="img/ev_1/espctrogramama2.png" alt="Espectrograma Tradicional">
                <p>Espectrograma Paramétrico</p>
            </div>
        </div>
        </div>
    </section>
</body>

<script>
        document.addEventListener('DOMContentLoaded', function() {
    // Pausar el otro audio cuando uno se reproduce
    const audioPlayers = document.querySelectorAll('.audio-player');
    
    audioPlayers.forEach(player => {
        player.addEventListener('play', function() {
            audioPlayers.forEach(otherPlayer => {
                if (otherPlayer !== player) {
                    otherPlayer.pause();
                }
            });
        });
    });
});
        document.addEventListener("DOMContentLoaded", function () {
        // Back button functionality to go to page_1.html
        const backButton = document.getElementById("back_button");

        backButton.addEventListener("click", function() {
            window.location.href = "page_1.html";  // Redirect to page_1.html
        });
    });
</script>
</html>
