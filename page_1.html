<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="icon" href="img/ev_1/logo.png" type="image/x-icon">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="tts_style.css">
    
    <title>TTS</title>
</head>
<body>
    <div id="tts_container">
    <div class="text-wrapper">
        <h1>
        <span class="pair">
            <span class="visible" id="t1">T</span>
            <span class="appear" id="a1">ext </span>
        </span>
        <span class="pair">
            <span class="visible" id="t2">T</span>
            <span class="appear" id="a2">o </span>
        </span>
        <span class="pair">
            <span class="visible" id="t3">S</span>
            <span class="appear" id="a3">peech</span>
        </span>
        </h1>
    </div>
    </div>

    <nav class="menu">

        <div class="submenu-container">
            <span class="menu-title">Síntesis</span>
            <div class="submenu">
            <a href="concatenativa.html">Concatenativa</a>
            <a href="parametrica.html">Paramétrica</a>
            <a href="neuronal.html">Neuronal</a>
            </div>
        </div>

        <a href="wavenet.html">WaveNet</a>
        <a href="GC_TTS.html">Google Cloud TTS</a>
        <a href="https://colab.research.google.com/drive/1bKdxU0kdXEUyUTttUzm1rCmTeJs1g6fP?usp=sharing" target="_blank">Notebook</a>
        <a href="bibliografia.html">Bibliografía</a>
        
        
    </nav>
    <div id="title">
        <h1>Objetivo</h1>
    </div>
    

    <p id="intro">
        Nuestro proyecto trata sobre los sistemas <i>Text To Speech</i>, y nuestra intención es ofrecer una visión clara de cómo ha progresado esta tecnología 
        a lo largo del tiempo, destacando los avances más novedosos relacionados con la síntesis neuronal, los distintos enfoques técnicos que han surgido, y las características que los diferencian entre sí. 
        Además, nuestro objetivo no es solo ofreceros una explicación teórica, sino también facilitar una experiencia interactiva. Para ello, hemos diseñado una página web en la que podáis 
        experimentar de forma práctica con diferentes ejemplos y herramientas que os proporcionamos. Así, podréis comprobar por vuestra propia mano cómo se transforma un texto en voz y 
        cómo varían los resultados según el tipo de sistema utilizado.
    </p>

    <h2>Evolución</h2>

    <div class="image-container" id="container1">
        <img src="img/ev_1/cursor.png" id="cursor">
        <img src="img/ev_1/mono1.png" alt="Image 1" id="mono1" class="ev_img">
        <img src="img/ev_1/mono2.png" alt="Image 2" id="mono2" class="ev_img">   
        <img src="img/ev_1/humano.png" alt="Image 3" id="humano" class="ev_img">
    </div>
    
    <div class="synthesis-container">
        <div class="synthesis-section" id="SC">
            <h3><span class="sintesis">Síntesis</span> <span class="glitch-text">Concatenativa</span></h3>
            <p>Los primeros sistemas <i>Text To Speech</i> funcionaban mediante la concatenación de fragmentos de audio grabados por una persona real.
                En este enfoque, se creaba una base de datos con pequeños fragmentos de sonido que correspondian a palabras, sílabas o fonemas y cuando el sistema debía leer un texto,
                buscaba y unía estos fragmentos para formar las palabras y frases, como si fuera un puzzle.
                </p>
                <p>Aunque este método permite crear voces sintéticas, presentaba limitaciones que se notaban en
                la falta de fluidez y naturalidad de las transiciones entre los sonidos y tiene problemas para generar frases no previamente definidas.
                A medida que la tecnología avanzaba, surgieron nuevos métodos como la síntesis paramétrica y, la novedad actual, la síntesis neural, que han permitido desarrollar
                sistemas <i>Text To Speech</i> mucho más naturales, capaces de imitar la voz humana</p>
            <ul>
                <li>
                    <span class="v_p">Ventajas:</span>
                    <p class="p_vd">La principal ventaja de la síntesis de voz concatenativa reside en la posibilidad de generar audio a partir de texto de una forma muy sencilla y que puede 
                        llegar a cumplir con una calidad media, especialmente si las unidades concatenadas han sido grabadas en contextos fonéticos similares. 
                        Además, una vez desarrollado, este sistema puede funcionar de manera bastante eficiente en tiempo real, sin necesidad de gran poder de cómputo, 
                        lo que lo hace adecuado para dispositivos con recursos limitados.</p>
                </li>
                <li>
                    <span class="v_p">Problemas:</span>
                    <p class="p_vd">Sin embargo, este enfoque presenta importantes limitaciones. Uno de sus principales inconvenientes es que al depender de una base de datos de 
                        grabaciones, la voz sintetizada solo puede reproducir combinaciones que ya estén incluidas o que puedan construirse a partir los archivos guardados. 
                        Esto provoca transiciones poco naturales entre fragmento y si las condiciones acústicas no coinciden perfectamente puede empeorar más. Además, requiere 
                        de esfuerzo en el proceso de grabación y el etiquetado inicial puede ser tedioso. Por último, no es posible modificar el estilo, la entonación o la emoción 
                        del habla sin rehacer las muestra de audio.</p>
                </li>
            </ul>

            <button id="test_button_c">¡Pruebalo!</button>
            
        </div>
        
        <div class="synthesis-section" id="SP">
            <h3><span class="sintesis">Síntesis</span> <span class="glitch-text">Paramétrica</span></h3>
            <p>Después llegaron los modelos matemáticos. En lugar de usar grabaciones completas, estos sistemas intentaron simular la voz humana mediante fórmulas y estadísticas. Utilizando modelos matemáticos, se podían generar sonidos de manera más flexible, sin depender de una base de datos pregrabada de palabras o fragmentos de audio. Estos modelos trabajaban creando las ondas sonoras a partir de parámetros calculados que replicaban las características del habla humana, como la frecuencia, la duración y el tono. Aunque este enfoque mejoró la fluidez y la capacidad de generar una variedad más amplia de sonidos, aún presentaba desafíos en términos de naturalidad, ya que no siempre lograba imitar perfectamente las sutilezas del lenguaje humano.</p>
            <ul>
                <li>
                    <span class="v_p">Ventajas:</span>
                    <ul>
                        <li>Requiere menos recursos computacionales que la síntesis neuronal, por lo que es más eficiente para dispositivos con poca potencia.</li>
                        <li>Es más fácil de controlar y ajustar parámetros específicos como tono, velocidad o entonación.</li>
                        <li>Puede generar voz en tiempo real sin necesidad de modelos pesados.</li>
                        <li>Ideal para sistemas embebidos, hardware limitado o aplicaciones donde la naturalidad no es prioritaria.</li>
                    </ul>
                </li>
                <li>
                    <span class="v_p">Problemas:</span>
                    <ul>
                        <li>La voz suena más robótica o artificial en comparación con la síntesis neuronal.</li>
                        <li>Limitada expresividad y menor capacidad de transmitir emociones humanas.</li>
                        <li>Menor calidad general del audio, especialmente en frases largas o complejas.</li>
                        <li>Menos adaptable a diferentes idiomas y acentos con resultados naturales.</li>
                    </ul>
                </li>
            </ul>

            <button id="test_button_p">¡Pruebalo!</button>
        </div>
        
        <div class="synthesis-section" id="SN">
            <h3><span class="sintesis">Síntesis</span> <span class="glitch-text">Neuronal</span></h3>
            <p>La gran revolución vino con las redes neuronales. Usando inteligencia artificial, se entrenan modelos que aprenden cómo suena el habla humana de verdad. Ya no se pegan sonidos ni se simulan con fórmulas; ahora se genera la voz desde cero, una muestra de audio a la vez. Estos modelos de aprendizaje profundo, como WaveNet o Tacotron, analizan grandes cantidades de datos de audio y aprenden las complejidades del habla, incluyendo la entonación, el ritmo y las emociones, lo que permite crear voces mucho más naturales y realistas. Gracias a esta tecnología, la síntesis de voz ha alcanzado un nivel de calidad que se acerca mucho más al habla humana auténtica, transformando la manera en que interactuamos con asistentes virtuales, audiolibros y otros sistemas TTS.</p>
            <ul>
                <li>
                    <span class="v_p">Ventajas:</span>
                    <ul>
                        <li>Sonido muy natural, con ritmo, entonación, pausas y hasta emociones. Mejoran constantemente con más datos y entrenamiento.</li>
                        <li>Genera voces más realistas y expresivas, ideales para aplicaciones conversacionales, audiolibros y asistentes virtuales.</li>
                        <li>Permite entrenar voces personalizadas, adaptadas a marcas, personajes o estilos específicos.</li>
                        <li>Capacidad de adaptación a diferentes idiomas y acentos con alta fidelidad.</li>
                    </ul>
                </li>
                <li>
                    <span class="v_p">Problemas:</span>
                    <ul>
                        <li>Necesitan mucha potencia de cálculo (aunque si se usan desde la nube como en Google Cloud, eso no es problema para el usuario).</li>
                        <li>Más difíciles de controlar sin herramientas específicas.</li>
                        <li>Requiere grandes volúmenes de datos para alcanzar calidad óptima.</li>
                        <li>Riesgo de uso malicioso, como deepfakes de voz o suplantación de identidad.</li>
                        <li>El costo computacional puede ser elevado para entrenamientos personalizados fuera de plataformas en la nube.</li>
                    </ul>
                </li>
            </ul>
            
            <button id="test_button_n">¡Pruebalo!</button>
           
        </div>
    </div>
    
    <div class="placeholder"></div>

</body>
<script src="tts_script.js"></script>
</html>
