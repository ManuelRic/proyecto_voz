<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="icon" href="img/ev_1/logo_pro.png">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="tts_style.css">
    
    <title>TTS</title>
</head>
<body>
    <div id="tts_container">
    <div class="text-wrapper">
        <h1>
        <span class="pair">
            <span class="visible" id="t1">T</span>
            <span class="appear" id="a1">ext </span>
        </span>
        <span class="pair">
            <span class="visible" id="t2">T</span>
            <span class="appear" id="a2">o </span>
        </span>
        <span class="pair">
            <span class="visible" id="t3">S</span>
            <span class="appear" id="a3">peech</span>
        </span>
        </h1>
    </div>
    </div>

    <nav class="menu">

        <div class="submenu-container">
            <span class="menu-title">Síntesis</span>
            <div class="submenu">
            <a href="concatenativa.html">Concatenativa</a>
            <a href="parametrica.html">Paramétrica</a>
            <a href="neuronal.html">Neuronal</a>
            </div>
        </div>

        <a href="wavenet.html">WaveNet</a>
        <a href="GC_TTS.html">Google Cloud TTS</a>
        <a href="https://colab.research.google.com/github/ManuelRic/Evolucion-TTS-Notebook/blob/main/Evolucion_TTS.ipynb" target="_blank">Notebook</a>
        <a href="bibliografia.html">Bibliografía</a>
        
        
    </nav>
    <div id="title">
        <h2 id="obje">Objetivo</h2>
    </div>
    

    <p id="intro">
        Nuestro proyecto trata sobre los sistemas <i>Text To Speech</i>, y nuestra intención es ofrecer una visión clara de cómo ha progresado esta tecnología 
        a lo largo del tiempo, destacando los avances más novedosos relacionados con la síntesis neuronal, los distintos enfoques técnicos que han surgido, y las características que los diferencian entre sí. 
        Además, nuestro objetivo no es solo ofreceros una explicación teórica, sino también facilitar una experiencia interactiva. Para ello, hemos diseñado una página web en la que podáis 
        experimentar de forma práctica con diferentes ejemplos y herramientas que os proporcionamos. Así, podréis comprobar por vuestra propia mano cómo se transforma un texto en voz y 
        cómo varían los resultados según el tipo de sistema utilizado.
    </p>

    <h2>Evolución</h2>

    <div class="image-container" id="container1">
        <img src="img/ev_1/cursor.png" id="cursor">
        <img src="img/ev_1/mono1.png" alt="Image 1" id="mono1" class="ev_img">
        <img src="img/ev_1/mono2.png" alt="Image 2" id="mono2" class="ev_img">   
        <img src="img/ev_1/humano.png" alt="Image 3" id="humano" class="ev_img">
    </div>
    
    <div class="synthesis-container">
        <div class="synthesis-section" id="SC">
            <h3><span class="sintesis">Síntesis</span> <span class="glitch-text">Concatenativa</span></h3>
            <p>Los primeros sistemas <i>Text To Speech</i> funcionaban mediante la concatenación de fragmentos de audio grabados por una persona real.
                En este enfoque, se creaba una base de datos con pequeños fragmentos de sonido que correspondian a palabras, sílabas o fonemas y cuando el sistema debía leer un texto,
                buscaba y unía estos fragmentos para formar las palabras y frases, como si fuera un puzzle.
                </p>
                <p>Aunque este método permite crear voces sintéticas, presentaba limitaciones que se notaban en
                la falta de fluidez y naturalidad de las transiciones entre los sonidos y tiene problemas para generar frases no previamente definidas.
                A medida que la tecnología avanzaba, surgieron nuevos métodos como la síntesis paramétrica y, la novedad actual, la síntesis neural, que han permitido desarrollar
                sistemas <i>Text To Speech</i> mucho más naturales, capaces de imitar la voz humana</p>
            <ul>
                <li>
                    <span class="v_p">Ventajas:</span>
                    <ul>
                        <li>Generación de audio de forma sencilla</li>
                        <li>Si las unidades concatenadas han sido grabadas en contextos fonéticos similares llega a tener una buena calidad</li>
                        <li>El sistema puede funcionar de manera bastante eficiente en tiempo real, 
                            sin necesidad de gran poder de cómputo</li>
                    </ul>
                </li>
                <li>
                    <span class="v_p">Problemas:</span>
                    <ul>
                        <li>La voz sintetizada solo puede reproducir combinaciones que ya estén incluidas o 
                            que puedan construirse a partir los archivos guardados. </li>
                        <li>Transiciones poco naturales entre fragmento y si las condiciones acústicas no coinciden perfectamente</li>
                        <li>No es posible modificar el estilo, la entonación o la emoción</li>
                    </ul>
                </li>
            </ul>

            <button id="test_button_c">¡Pruebalo!</button>
            
        </div>
        
        <div class="synthesis-section" id="SP">
            <h3><span class="sintesis">Síntesis</span> <span class="glitch-text">Paramétrica</span></h3>
            <p>Los sistemas paramétricos representaron un avance significativo frente a la concatenación tradicional. En lugar de unir fragmentos pregrabados, estos modelos generan el audio mediante algoritmos matemáticos que simulan el tracto vocal humano. Utilizan parámetros acústicos como:</p>
    
    <ul id="bullet_p">
        <li>Frecuencia fundamental (F0) para el tono</li>
        <li>Coeficientes espectrales para los formantes</li>
        <li>Parámetros de excitación para las consonantes</li>
    </ul>
    
    <p>El enfoque más común fue el <strong>vocoder paramétrico</strong>, que analizaba grabaciones reales para extraer estos parámetros
         y luego los usaba para sintetizar nuevas frases. Aunque superaba los problemas de discontinuidad de la concatenación, introducía 
         sus propias limitaciones en calidad y naturalidad.</p>
    
    <ul>
        <li>
            <span class="v_p">Ventajas:</span>
            <ul>
                <li>Mayor flexibilidad que la concatenación al no depender de unidades pregrabadas</li>
                <li>Permite modificar parámetros como velocidad, tono y timbre de forma independiente</li>
                <li>Requiere menos almacenamiento que bases de datos de audio completas</li>
            </ul>
        </li>
        <li>
            <span class="v_p">Problemas:</span>
            <ul>
                <li>Calidad de voz "robótica" debido a la simplificación del modelo acústico</li>
                <li>Dificultad para capturar la naturalidad de la voz</li>
                <li>Limitada capacidad para expresar emociones o estilos de habla</li>
            </ul>
        </li>
    </ul>

    <button id="test_button_p">¡Pruebalo!</button>
</div>
        </div>
        
        <div class="synthesis-section" id="SN">
            <h3><span class="sintesis">Síntesis</span> <span class="glitch-text">Neuronal</span></h3>
            <p>La gran revolución vino con las redes neuronales. Usando inteligencia artificial, se entrenan modelos que aprenden cómo suena el habla humana de verdad. Ya no se pegan sonidos ni se simulan con fórmulas; ahora se genera la voz desde cero, una muestra de audio a la vez. Estos modelos de aprendizaje profundo, como WaveNet o Tacotron, analizan grandes cantidades de datos de audio y aprenden las complejidades del habla, incluyendo la entonación, el ritmo y las emociones, lo que permite crear voces mucho más naturales y realistas. Gracias a esta tecnología, la síntesis de voz ha alcanzado un nivel de calidad que se acerca mucho más al habla humana auténtica, transformando la manera en que interactuamos con asistentes virtuales, audiolibros y otros sistemas TTS.</p>
            <ul>
                <li>
                    <span class="v_p">Ventajas:</span>
                    <ul>
                        <li>Sonido muy natural, con ritmo, entonación, pausas y hasta emociones. Mejoran constantemente con más datos y entrenamiento.</li>
                        <li>Genera voces más realistas y expresivas, ideales para aplicaciones conversacionales, audiolibros y asistentes virtuales.</li>
                        <li>Permite entrenar voces personalizadas, adaptadas a marcas, personajes o estilos específicos.</li>
                    </ul>
                </li>
                <li>
                    <span class="v_p">Problemas:</span>
                    <ul>
                        <li>Necesitan mucha potencia de cálculo (aunque si se usan desde la nube como en Google Cloud, eso no es problema para el usuario).</li>
                        <li>Más difíciles de controlar sin herramientas específicas.</li>
                        <li>Requiere grandes volúmenes de datos para alcanzar calidad óptima.</li>
                        <li>Riesgo de uso malicioso, como deepfakes de voz o suplantación de identidad.</li>
                        <li>El costo computacional puede ser elevado para entrenamientos personalizados fuera de plataformas en la nube.</li>
                    </ul>
                </li>
            </ul>
            
            <button id="test_button_n">¡Pruebalo!</button>
           
        </div>
    </div>
    
    <div class="placeholder"></div>

</body>
<script src="tts_script.js"></script>
</html>
